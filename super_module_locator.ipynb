{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import find_peaks\n",
    "import csv\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation data:\n",
    "\n",
    "val_coords = {'B755':{'vert_lines':[1703, 3110], 'hor_lines':[1273]},\n",
    "'B756': {'vert_lines':[1933], 'hor_lines':[1299]},\n",
    "'B757': {'vert_lines':[910, 2293], 'hor_lines':[1266]},\n",
    "'B761': {'vert_lines':[2286], 'hor_lines':[1246]},\n",
    "'B762': {'vert_lines':[1270, 2576], 'hor_lines':[1266]},\n",
    "'B763': {'vert_lines':[1706, 3026], 'hor_lines':[2203]},\n",
    "'B766': {'vert_lines':[1463, 2886], 'hor_lines':[1256]},\n",
    "'B773': {'vert_lines':[950, 2306], 'hor_lines':[1246]},\n",
    "'B780': {'vert_lines':[2123], 'hor_lines':[1250]},\n",
    "'B782': {'vert_lines':[1370, 2936], 'hor_lines':[1236]},\n",
    "'B784': {'vert_lines':[2150], 'hor_lines':[1243]},\n",
    "'B786': {'vert_lines':[1293, 2809], 'hor_lines':[1250]},\n",
    "'B788': {'vert_lines':[2173], 'hor_lines':[1219]},\n",
    "'B790': {'vert_lines':[1203, 2810], 'hor_lines':[1256]},\n",
    "'B765': {'vert_lines':[2310], 'hor_lines':[1259]},\n",
    "'B768': {'vert_lines':[2100], 'hor_lines':[1263]},\n",
    "'B769': {'vert_lines':[2383], 'hor_lines':[1266]},\n",
    "'B770': {'vert_lines':[2733, 1383], 'hor_lines':[1276]},\n",
    "'B772': {'vert_lines':[2046], 'hor_lines':[1263]},\n",
    "'B774': {'vert_lines':[1463, 2783], 'hor_lines':[1256]},\n",
    "'B775': {'vert_lines':[1789], 'hor_lines':[1236]},\n",
    "'B776': {'vert_lines':[1956], 'hor_lines':[1273]},\n",
    "'B777': {'vert_lines':[2369], 'hor_lines':[1253]},\n",
    "'B800': {'vert_lines':[1436, 2766], 'hor_lines':[1263]},\n",
    "'B901': {'vert_lines':[1683], 'hor_lines':[1236]},\n",
    "'B902': {'vert_lines':[2089], 'hor_lines':[1279]},    #64 lines above here\n",
    "\n",
    "    }\n",
    "val_names = val_coords.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image preprocessing functions\n",
    "#if usig BGR masks, not needed if regular grayscale ones are used\n",
    "def ConvertMasksBGR(BGR_img) :\n",
    "    lower_pmts = np.array([250, 0, 0], dtype = \"uint16\")\n",
    "    upper_pmts = np.array([255,0,0], dtype = \"uint16\")\n",
    "    pmt_mask = cv2.inRange(BGR_img, lower_pmts, upper_pmts)\n",
    "    pmt_mask = cv2.cvtColor(pmt_mask, cv2.COLOR_GRAY2BGR)\n",
    "   # print(pmt_mask.shape)\n",
    "    pmt_mask[pmt_mask == 255] = 1\n",
    "    return pmt_mask\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "def UndistortImage(orig) :\n",
    "    #undistorted = orig.copy();\n",
    "\n",
    " # //Mat cameraMatrix = Mat::eye( 3, 3, CV_64F ); //K\n",
    " # //Mat distCoeffs = Mat::zeros( 1, 4, CV_64F ); //D\n",
    " # //  Here's the constants extracted directly from MATLAB:\n",
    " # //           FocalLength: [2.7605e+03 2.7670e+03]\n",
    " # //        PrincipalPoint: [1.9143e+03 1.5964e+03]\n",
    " # //             ImageSize: [3000 4000]\n",
    " # //      RadialDistortion: [-0.2398 0.1145]\n",
    " # //  TangentialDistortion: [0 0]\n",
    " # //               Skew: 0\n",
    " # //  \n",
    " # // The intrinsics fx, fy, cx and cy in your intrinsics matrix are the\n",
    " # // focal length and principle point above, and are dependant on the\n",
    "  #// image size so best to make sure the images you're using haven't\n",
    "  #// been rescaled.\n",
    "  ##// The four values only give the minimum k1, k2, p1, p2 that you need \n",
    "  #// because calibrating additional parameters weren't enabled by the \n",
    "  #// students when they did this calibration. Tangential distortion is set to \n",
    "  #// zero because it was also disabled.  \n",
    "\n",
    "    cameraMatrix = np.array([[ 2.7605e+03,      0,          1.9143e+03],\n",
    "                        [0,               2.7670e+03,      1.5964e+03], \n",
    "                        [0,                    0,               1]] )\n",
    "    \n",
    "    distCoeffs = np.array( [-0.2398, 0.1145, 0, 0] )\n",
    " #   print(cameraMatrix)\n",
    "    undistorted = cv2.undistort(orig, cameraMatrix, distCoeffs);\n",
    "\n",
    "    return undistorted;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peak picking funcs\n",
    "\n",
    "\n",
    "#stolen from stack overflow \n",
    "#this is set up for a multi peak gaussian fit \n",
    "def peaks_func(x, *params):\n",
    "    #print(params)\n",
    "    y = np.zeros_like(x)\n",
    "    for i in range(0, len(params), 3):\n",
    "        ctr = params[i]\n",
    "        amp = params[i+1]\n",
    "        wid = params[i+2]\n",
    "        y = y + amp * np.exp( -((x - ctr)/wid)**2)\n",
    "    return y\n",
    "\n",
    "\n",
    "#################################################################\n",
    "#guess locations of peaks using a threshold and data above, \n",
    "#instead of fitting to peaks, just see where peak goes above and below average and get centre of those two point\n",
    "\n",
    "def peak_guess(x_dat, y_dat) : \n",
    "    tempx = []\n",
    "    tempy = []\n",
    "    peak_loc = []\n",
    "    \n",
    "    #if it is above this it is a peak\n",
    "    #peak_thresh = np.min(y_dat) + (np.max(y_dat) - np.min(y_dat))*0.5\n",
    "    peak_thresh = np.average(y_dat)\n",
    "    for i in range(len(y_dat)) :\n",
    "        if y_dat[i] >= peak_thresh :\n",
    "            on_peak = True\n",
    "            tempx.append(x_dat[i])\n",
    "            tempy.append(y_dat[i])\n",
    "        else :\n",
    "        #should only do this AFTER end of peak\n",
    "            if len(tempx) > 10 : #no empty data\n",
    "                #print([tempy[0], tempy[-1], len(tempy)])\n",
    "\n",
    "                #if int(np.abs(tempy[0] - tempy[-1])) < 500: #check that it is a full peak\n",
    "                peak_start = tempx[0]\n",
    "                peak_end = tempx[-1]\n",
    "                peak_cen = peak_start + (peak_end - peak_start) / 2\n",
    "                peak_max = np.max(tempy)\n",
    "                peak_wid = peak_end - peak_start\n",
    "\n",
    "                peak_loc.append([peak_cen, peak_max, peak_wid])\n",
    "            tempx = []\n",
    "            tempy = []\n",
    "    return peak_loc, peak_thresh\n",
    "\n",
    "####################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drawing various lines \n",
    "#peaks is the pmt lines, margins are the image crops that remove the edges of images and need to be accounted for \n",
    "#super module lines are recalculated in here\n",
    "\n",
    "def draw_lines(img_in, peaks1, peaks2, margin1, margin2,  draw_pmt_lines = True) :\n",
    "    global smod_count_num\n",
    "    global smod_count_lines\n",
    "    \n",
    "    #make a new instance, may be unnecessary but really dont want to draw over data \n",
    "    img = img_in.copy()\n",
    "    if draw_pmt_lines == True :\n",
    "        if len(peaks1) > 8 :\n",
    "            num_rem1 = 2\n",
    "        else :\n",
    "            num_rem1 = 1\n",
    "        \n",
    "        if len(peaks2) > 8:\n",
    "            num_rem2 = 2\n",
    "        else :\n",
    "            num_rem2 = 1\n",
    "                       \n",
    "            \n",
    "       # cv2.line(img, (0, int(peaks1[0])), (img.shape[1], int(peaks1[0])),  color=[255, 0, 255] , thickness=2)\n",
    "       # cv2.line(img, (0, int(peaks1[-1])), (img.shape[1], int(peaks1[-1])),  color=[255, 0, 255] , thickness=2)\n",
    "\n",
    "        for i in range(0, len(peaks1)) :\n",
    "            if (i < num_rem1) or (i >= len(peaks1)-num_rem1):\n",
    "                cv2.line(img, (0, int(peaks1[i]) + margin1), (img.shape[1], int(peaks1[i] + margin1)),  color=[255, 0, 255] , thickness=2)\n",
    "            else :\n",
    "                cv2.line(img, (0, int(peaks1[i]) + margin1), (img.shape[1], int(peaks1[i] + margin1)),  color=[0, 0, 255] , thickness=2)\n",
    "\n",
    "        for j in range(0, len(peaks2)) :\n",
    "            if (j < num_rem2) or (j >= len(peaks2)-num_rem2) :\n",
    "                cv2.line(img, (int(peaks2[j] + margin2), 0), (int(peaks2[j] + margin2), img.shape[0]),  color=[255, 0, 255] , thickness=2) #PUT IN ANGLE CORRECTION\n",
    "            else :\n",
    "                cv2.line(img, (int(peaks2[j] + margin2), 0), (int(peaks2[j] + margin2), img.shape[0]),  color=[0, 0, 255] , thickness=2)\n",
    "                \n",
    "                \n",
    "    super_x, gaps = super_lines(peaks1, \"x\")\n",
    "    super_y, gaps = super_lines(peaks2, \"y\")   \n",
    "    \n",
    "    for k in range(0, len(super_x)) :\n",
    "        cv2.line(img, (0, int(super_x[k] + margin1)), (img.shape[1], int(super_x[k] + margin1)),  color=[0, 255, 0] , thickness=4)\n",
    "        \n",
    "    for l in range(0, len(super_y)) :\n",
    "        \n",
    "        cv2.line(img, (int(super_y[l] + margin2), 0), (int(super_y[l] + margin2), img.shape[0]),  color=[0, 255, 0] , thickness=4)\n",
    "        #cv2.putText(img, f'{smod_count_num}', (int(super_y[l] + margin2), int(img.shape[0]/2 + margin2)), cv2.FONT_HERSHEY_SIMPLEX, 3, (0,255,0), 2)\n",
    "        #smod_count_lines.append([super_y[l], smod_count_num])\n",
    "        #smod_count_num += 1\n",
    "            \n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "######Questionable methods begin here\n",
    "def super_lines(pmt_lines_long, axis) :\n",
    "    \n",
    "    #_long is all lines, remove outer lines as they can be wrong\n",
    "    super_mod_lines = []\n",
    "    if len(pmt_lines_long) > 8 :\n",
    "        num_rem = 2\n",
    "    else :\n",
    "        num_rem = 1\n",
    "\n",
    "    pmt_lines = pmt_lines_long[num_rem:-num_rem]\n",
    "\n",
    "    #for i in range(0, len(popt), 3) :\n",
    "     #   pmt_lines.append(popt[i])\n",
    "    \n",
    "    #IT WOULD BE NICE TO GET AN IMAGE INDEPENDEDNT MEASURE OF GAPS E.G. BASED OFF OF PMT WIDTH  \n",
    "    gaps_long = np.diff(pmt_lines_long)\n",
    "    gaps = np.diff(pmt_lines)\n",
    "    \n",
    "    #Pattern test horizontal lines\n",
    "    #have three possibilities: 1st, 2nd, 3rd gap is a super module\n",
    "    #split gap dat into predicted large and small gaps\n",
    "    #small gap data is more reliable as there are more of them\n",
    "    #True small gap data will have small difference between gap sizes, false ones will contain large and small gaps so difference will be larger\n",
    "    #there is probably a case where this is not true\n",
    "    if axis == \"x\" :\n",
    "        #hypothesis that first gap is super module\n",
    "        \n",
    "        hyp1 = {'sindx':range((num_rem)%3,len(gaps_long), 3), 'hi':gaps[::3], 'lo':np.setdiff1d(gaps,gaps[::3]), \n",
    "                'long_hi':gaps_long[(num_rem)%3::3]}\n",
    "        hyp2 = {'sindx':range((1 + num_rem)%3,len(gaps_long), 3), 'hi':gaps[1::3], 'lo':np.setdiff1d(gaps,gaps[1::3]), \n",
    "                'long_hi':gaps_long[(num_rem+1)%3::3]}\n",
    "        hyp3 = {'sindx':range((2 + num_rem)%3,len(gaps_long), 3), 'hi':gaps[2::3], 'lo':np.setdiff1d(gaps,gaps[2::3]),\n",
    "                'long_hi':gaps_long[(num_rem+2)%3::3]}\n",
    "        \n",
    "        hyps = [hyp1, hyp2, hyp3]\n",
    " #       print(hyps)\n",
    "        scores =[] \n",
    "        for i in range(len(hyps)):\n",
    "                scores.append(np.max(hyps[i]['lo']) - np.min(hyps[i]['lo']))\n",
    "                #scores.append(np.max(hyps[i]['hi'])) \n",
    "        best = scores.index(min(scores))\n",
    "        \n",
    "\n",
    "    #Simpler: average of large gap data will be larger than average of small gap\n",
    "    #more gaps avai;lable so I think this is safe\n",
    "    if axis == \"y\" :\n",
    "        #ase for every other gap (modules)\n",
    "      #  hyp1 = {'sindx':range(0,len(gaps), 2),'hi':gaps[::2], 'lo':np.setdiff1d(gaps,gaps[::2])}\n",
    "      #  hyp2 = {'sindx':range(1,len(gaps), 2),'hi':gaps[1::2], 'lo':np.setdiff1d(gaps,gaps[1::2])}\n",
    "      #  hyps = [hyp1, hyp2]\n",
    "      #  if np.average(hyp1['hi']) > np.average(hyp2['hi']) :\n",
    "      #      best = 0\n",
    "      #  else :\n",
    "      #      best = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "        #mark supermodules like previously\n",
    "        hyp1 = {'sindx':range((num_rem)%4,len(gaps_long), 4),'hi':gaps[::4], 'lo':np.setdiff1d(gaps,gaps[::4]), \n",
    "                'long_hi':gaps_long[(num_rem)%4::4]}\n",
    "        hyp2 = {'sindx':range((1 + num_rem)%4,len(gaps_long), 4),'hi':gaps[1::4], 'lo':np.setdiff1d(gaps,gaps[1::4]), \n",
    "                'long_hi':gaps_long[(num_rem+1)%4::4]}\n",
    "        hyp3 = {'sindx':range((2 + num_rem)%4,len(gaps_long), 4),'hi':gaps[2::4], 'lo':np.setdiff1d(gaps,gaps[2::4]),\n",
    "                'long_hi':gaps_long[(num_rem+2)%4::4]}\n",
    "        hyp4 = {'sindx':range((3 + num_rem)%4,len(gaps_long), 4),'hi':gaps[3::4], 'lo':np.setdiff1d(gaps,gaps[3::4]),\n",
    "                'long_hi':gaps_long[(num_rem+3)%4::4]}\n",
    "        \n",
    "        hyps = [hyp1, hyp2, hyp3, hyp4]\n",
    "\n",
    "        #print(gaps)\n",
    "        #print(hyp1['lo'])\n",
    "        #print(hyp2['lo'])\n",
    "        #print(hyp3['lo'])\n",
    "        #print(hyp4['lo'])\n",
    "\n",
    "        \n",
    "        scores =[] \n",
    "        for j in range(len(hyps)):\n",
    "                #scores.append(np.max(hyps[j]['lo']) - np.min(hyps[j]['lo']))\n",
    "                #scores.append(np.max(hyps[j]['hi'])) \n",
    "                scores.append(np.average(hyps[j]['lo']))\n",
    "            \n",
    "        best = scores.index(min(scores))\n",
    "      # print(f'y hypothesis:{hyps}')        \n",
    "    \n",
    "            \n",
    "    \n",
    "    for k in hyps[best]['sindx'] :\n",
    "        if k != len(pmt_lines_long) :\n",
    "            super_mod_lines.append(pmt_lines_long[k] + (pmt_lines_long[k+1] - pmt_lines_long[k])/2)\n",
    "    \n",
    "    return super_mod_lines, hyps[best]['hi']\n",
    "#################################################################\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(img, angle) :\n",
    "    #get grayscale so only 2d matrix\n",
    "    gray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img_size = gray_img.shape\n",
    "    x_score = []\n",
    "    y_score = []\n",
    "    mult = 2    #how many lines skipped in image scan (1 is dto get a score for every line)\n",
    "    thresh = 1000    #threshold for pixel scores\n",
    "\n",
    "\n",
    "    #loop over a and y with lines drawn on a mask to get score from pixel sums\n",
    "   # print(img_size)\n",
    "    for i in np.linspace(0, img_size[0], int(img_size[0]/mult)) :\n",
    "        img_mask = np.zeros(img_size,dtype=np.uint8)\n",
    "        start_y = int(i)\n",
    "        end_y = start_y + int(angle*img_size[1])  #minus because coords measured from top left corner\n",
    "        cv2.line(img_mask, (0, start_y), (img_size[1], end_y),  color=1 , thickness=1)\n",
    "\n",
    "\n",
    "        fit = gray_img*img_mask\n",
    "        \n",
    "        #DEBUG\n",
    "        #print(np.unique(fit))\n",
    "        #if(fit.all()<1) :\n",
    "        #    continue     \n",
    "        #init_rad = circ_r\n",
    "      # cv2.imshow(\"img\", gray_img)\n",
    "      # cv2.waitKey(0)\n",
    "    \n",
    "        score = np.sum(fit)\n",
    "        x_score.append(score)\n",
    "        \n",
    "\n",
    "    for j in np.linspace(0, img_size[1], int(img_size[1]/mult)) :\n",
    "        img_mask = np.zeros(img_size,dtype=np.uint8)\n",
    "        start_x = int(j)\n",
    "        end_x = start_x - int(angle*img_size[0])\n",
    "        cv2.line(img_mask, (start_x, 0), (end_x, img_size[0]),  color=1 , thickness=1)\n",
    "\n",
    "        fit = gray_img*img_mask\n",
    "\n",
    "        score = np.sum(fit)\n",
    "        y_score.append(score)\n",
    "\n",
    "    return x_score, y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDAATE this code to not use circles, maximise score, may be longer but faaar better\n",
    "def get_angle(in_img) :\n",
    "    \n",
    "    img = in_img.copy()\n",
    "    \n",
    "    gray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img_size = gray_img.shape\n",
    "    gray_img[gray_img > 0] = 100\n",
    "    gray_img = gray_img[500:-500, :] \n",
    "   # print(np.unique(gray_img))\n",
    "    edges = cv2.Canny(gray_img,0,100)\n",
    "    circles = cv2.HoughCircles(edges,cv2.HOUGH_GRADIENT,dp=1,\n",
    "                           minDist=200,\n",
    "                           param1=100,\n",
    "                           param2=20,\n",
    "                           minRadius=140,\n",
    "                           maxRadius=200\n",
    "                          )\n",
    "        #print(circles)\n",
    "        \n",
    "    #x, y data for circle centers\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    circ_x = []\n",
    "    circ_y = []\n",
    "    for i in circles[0, :] :\n",
    "        cv2.circle(img,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "        #print(i[0], i[1])\n",
    "        circ_x.append(i[0])\n",
    "        circ_y.append(i[1])\n",
    "  #  print(np.min(circ_y))\n",
    "  #  print(np.max(circ_y))\n",
    "    \n",
    "    \n",
    "    #Get the first row of circles\n",
    "    circ_x_first = []\n",
    "    circ_y_first = []\n",
    "    min_y = np.min(circ_y)\n",
    "    \n",
    "    #for drawing circles\n",
    "    for i in range(len(circ_y)) :\n",
    "        if circ_y[i] <  2*min_y :\n",
    "         #   circ_y.pop(i)\n",
    "          #  circ_x.pop(i)\n",
    "            circ_x_first.append(circ_x[i])\n",
    "            circ_y_first.append(circ_y[i])\n",
    "                                \n",
    "    for i in range(len(circ_x_first)) :\n",
    "        cv2.circle(img, (circ_x_first[i], circ_y_first[i]), 100, (0,255,0), -1)\n",
    "    \n",
    "    #straight line function\n",
    "    def func(x, a, b) :\n",
    "        return a*x + b\n",
    "    popt, pcov = curve_fit(func, circ_x_first, circ_y_first)\n",
    "    \n",
    "    \n",
    "   #print(popt)\n",
    "    #print(circ_x)\n",
    "    #print(circ_y)\n",
    "    #cv2.imshow('img', img)\n",
    "    #cv2.waitKey(0)\n",
    "    return popt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(x1, y1, pmt_lines_1, x2, y2, pmt_lines_2) :\n",
    "\n",
    "    #IT WOULD BE NICE TO GET AN IMAGE INDEPENDEDNT MEASURE OF GAPS E.G. BASED OFF OF PMT WIDTH  \n",
    "    gaps1 = np.diff(pmt_lines_1)\n",
    "    gaps2 = np.diff(pmt_lines_2)\n",
    "    gap_x_1 = []\n",
    "    gap_x_2 = []\n",
    "    \n",
    "    for k in range(len(gaps1)) :\n",
    "        gap_x_1.append(pmt_lines_1[k] + gaps1[k]/2)\n",
    "        \n",
    "    for l in range(len(gaps2)) :\n",
    "        gap_x_2.append(pmt_lines_2[l] + gaps2[l]/2)\n",
    "    \n",
    "    #plot setup\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10,6), sharex='col')\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(left = 0.1, bottom = 0.1, hspace=0.4, wspace=0.2)\n",
    "\n",
    "\n",
    "    axs[0, 0].plot(x1, y1) #line scores\n",
    "    for i in pmt_lines_1 :\n",
    "        axs[0, 0].axvline(x=i)\n",
    "    #axs[0, 0].axhline( thresh1, color = 'g', label='thresh')\n",
    "    axs[0,0].set_title(\"Horizontal line scan\")\n",
    "    axs[0,0].set_xlabel(\"X position (px)\")\n",
    "    axs[0,0].set_ylabel(\"Score (px)\")\n",
    "\n",
    "    \n",
    "    axs[0, 1].plot(x2, y2) \n",
    "    for j in pmt_lines_2 :\n",
    "        axs[0, 1].axvline(x=j)\n",
    "\n",
    "    #axs[0, 1].axhline( thresh2, color = 'g', label='thresh')\n",
    "    axs[0, 1].set_title(\"Vertical line scan\")\n",
    "    axs[0,1].set_xlabel(\"Y position (px)\")\n",
    "    axs[0,1].set_ylabel(\"Score (px)\")\n",
    "\n",
    "    #decision polots\n",
    "    #TODO: put predicted lines on here?\n",
    "    axs[1, 0].set_title(\"Horizontal super module decision\")\n",
    "    axs[1, 0].scatter(gap_x_1, gaps1, label='gaps')\n",
    "    axs[1, 0].axhline( np.median(gaps1), color = 'r', label='median')\n",
    "    axs[1, 0].axhline( np.average(gaps1), color = 'b', label='average')\n",
    "    axs[1, 0].legend(loc=\"upper right\", prop={'size': 6})\n",
    "    axs[1,0].set_xlabel(\"X position (px)\")\n",
    "    axs[1,0].set_ylabel(\"Gap size (px)\")\n",
    "\n",
    "    axs[1, 1].set_title(\"Vertical super module decision\")\n",
    "    axs[1, 1].scatter(gap_x_2, gaps2, label='gaps' )\n",
    "    axs[1, 1].axhline( np.median(gaps2), color = 'r', label='median')\n",
    "    axs[1, 1].axhline( np.average(gaps2), color = 'b', label='average')\n",
    "    axs[1, 1].legend(loc=\"upper right\", prop={'size': 6})\n",
    "    axs[1,1].set_xlabel(\"Y position (px)\")\n",
    "    axs[1,1].set_ylabel(\"Gap size (px)\")\n",
    "\n",
    "    axs[0, 0].tick_params(reset=True)\n",
    "    axs[0, 1].tick_params(reset=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_super_modules(indir, outdir, name,  shift_info=[[], 1]) :\n",
    "    global smod_track_num\n",
    "    global prev_img_end_num\n",
    "    global failed_imgs\n",
    "    global prev_hor_end_num\n",
    "    \n",
    "    img_in = cv2.imread(f'{indir}{name}.png')\n",
    "    #read image\n",
    "\n",
    "    \n",
    "    base_name = name[:4]\n",
    "    print(base_name)\n",
    "    #if gray mask :\n",
    "    #img_in[img_in == 2] = 0\n",
    "\n",
    "    #if bgr mask :\n",
    "    img_in = ConvertMasksBGR(img_in)\n",
    "\n",
    "\n",
    "    #Undistort image\n",
    "    imge = UndistortImage(img_in)\n",
    "    #imge = img_in\n",
    "    \n",
    "    #choose output image to be recoloured mask, or overlaid on original\n",
    "    #line_img = cv2.imread(f'/home/dm3315/Documents/SK/PMT_learning/images/Raw/ring_avg/udist/{name[:8]}.png')\n",
    "    line_img = imge.copy()\n",
    "    line_img[line_img < 1] = 100  #is using same input\n",
    "\n",
    "    \n",
    "    #Crop to central region\n",
    "    hor_margin = 200 #cuts on x axis\n",
    "    vert_margin = 100 #cuts on y axis\n",
    "    imge = imge[hor_margin:-hor_margin, vert_margin:-vert_margin, :]\n",
    "    \n",
    "    #DEBUG\n",
    "   # print(np.unique(imge))\n",
    "    #cv2.imshow(\"img\", imge)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "    #Scan in x and y a line with the angle above and count the number of pixels that appear in the PMT mask\n",
    "    x_line_score, y_line_score = get_scores(imge, 0)# angle)\n",
    "    mult = 2 #for speed\n",
    "    x1 = np.linspace(0, imge.shape[0], int(imge.shape[0]/mult))\n",
    "    x2 = np.linspace(0, imge.shape[1], int(imge.shape[1]/mult))\n",
    "\n",
    "    #Get approximate locations of peaks -  centre of pmt lines\n",
    "    peak_loc_1, guess_thresh_1 = peak_guess(x1, x_line_score)\n",
    "    peak_loc_2, guess_thresh_2 = peak_guess(x2, y_line_score)\n",
    "    \n",
    "    \n",
    "    ##DEBUG\n",
    "    #plt.plot(x1, x_line_score)\n",
    "    #plt.plot(x2, y_line_score)\n",
    "    #print(peak_loc_1)\n",
    "    #print(peak_loc_2)\n",
    "    \n",
    "    \n",
    "    #Peak finding methods, three are implemented at the moment\n",
    "    print(f\"Guess: {len(peak_loc_1)} horizontal gaps above {guess_thresh_1}, {len(peak_loc_2)} vertical above {guess_thresh_2}\")\n",
    "\n",
    "    #Do a gaussian fit with an inital guess from above\n",
    "   # popt1, pcov1 = curve_fit(peaks_func, x1, x_line_score, p0=peak_loc_1)\n",
    "   # popt2, pcov2 = curve_fit(peaks_func, x2, y_line_score, p0=peak_loc_2)\n",
    "\n",
    "    #scipy function\n",
    "    peak_index_x, _ = find_peaks(np.array(x_line_score),  distance=100, prominence=500, width=10) #\\\n",
    "                                              #height=guess_thresh_1, \\\n",
    "                                              #\\ \n",
    "                                 #np.abs(np.average(np.diff(peak_loc_1)))*0.5, \n",
    "                                               #\\\n",
    "                                              \n",
    "    \n",
    "    peak_index_y, _ = find_peaks(np.array(y_line_score), distance=100, prominence=500, width = 10)\n",
    "                                              #height=guess_thresh_2, \\\n",
    "                                               #\\  #np.abs(np.average(np.diff(peak_loc_2)))*0.5, \n",
    "                                               #\\\n",
    "                                              \n",
    "\n",
    "  #  print(peak_index_x)\n",
    "  #  print(peak_index_y)\n",
    "    \n",
    "    #find peak centers with different methods\n",
    "    peaks_x_1 = x1[peak_index_x]\n",
    "    peaks_y_1 = x2[peak_index_y]\n",
    "    \n",
    "    #guess  method\n",
    "   # peaks_x_2 = peak_loc_1\n",
    "   # peaks_y_2 = peak_loc_2 \n",
    "    peaks_x_2 = []\n",
    "    peaks_y_2 = []\n",
    "    for i in peak_loc_1 :\n",
    "        peaks_x_2.append(i[0])\n",
    "\n",
    "    for i in peak_loc_2 :\n",
    "        peaks_y_2.append(i[0])\n",
    "    \n",
    "    \n",
    "    #FIT METHOD\n",
    "    '''\n",
    "    fit1 = peaks_func(x1, *popt1)\n",
    "    fit2 = peaks_func(x2, *popt2)    \n",
    "    peaks_x_3 = []\n",
    "    peaks_y_3 = []\n",
    "    for i in range(0, len(popt1), 3) :\n",
    "        peaks_x_3.append(popt1[i])\n",
    "    \n",
    "    for j in range(0, len(popt2), 3) :\n",
    "        peaks_y_3.append(popt2[j])\n",
    "    '''    \n",
    "    \n",
    "    #Choose a method\n",
    "    peaks_x = peaks_x_2\n",
    "    peaks_y = peaks_y_2\n",
    "\n",
    "    #get super module lines\n",
    "    super_x, gaps_x = super_lines(peaks_x, \"x\")\n",
    "    super_y, gaps_y = super_lines(peaks_y, \"y\")\n",
    "    \n",
    "    ##TODO: Use tracknum to compare if it is close to smod lines found and then set track_num to whatever is the first one \n",
    "    \n",
    "    #Draw lines on image for reference\n",
    "    line_img_drawn = draw_lines(line_img, peaks_x, peaks_y, hor_margin, vert_margin,  draw_pmt_lines = True)\n",
    "    img_vert_lines = []     #[[super_y, num]...]\n",
    "    img_hor_lines = []\n",
    "    pred_vert_lines = shift_info[0]\n",
    "    \n",
    "    #should only be the case for first image, also catches if drone moves too far in which case will likely be wrong\n",
    "    if len(pred_vert_lines) == 0 :\n",
    "        for new_line in super_y :\n",
    "            prev_img_end_num += 1\n",
    "            img_vert_lines.append([new_line+ vert_margin, prev_img_end_num])\n",
    "        for new_hor_line in range(len(super_x)) :\n",
    "            temp_hor_num = prev_hor_end_num + new_hor_line\n",
    "            img_hor_lines.append([super_x[new_hor_line]+hor_margin, temp_hor_num+1])\n",
    "    else :\n",
    "        #print(pred_vert_lines.shape)\n",
    "        num_prev = len(pred_vert_lines)\n",
    "        num_current = len(super_y)\n",
    "        cor_lines = []   #predicted lines corrected for this image\n",
    "        cor_num = []     #predicted line numbers\n",
    "        for ucor_line in range(num_prev) :\n",
    "                cor_lines.append(pred_vert_lines[ucor_line][0] * np.average(np.diff(super_y)))\n",
    "                cor_num.append(pred_vert_lines[ucor_line][1])\n",
    "\n",
    "        print(f'max_lines:{np.max(cor_lines)}')\n",
    "        print(f'max_num:{np.max(cor_num)}')\n",
    "        print(f'info:{pred_vert_lines}')\n",
    "        print(f'old lines:{cor_lines}')\n",
    "        print(f'new_lines {super_y}  {super_x}')\n",
    "\n",
    "\n",
    "        max_prev_line = np.max(cor_lines)\n",
    "        max_prev_num = np.max(cor_num)\n",
    "\n",
    "        #Label smod lines\n",
    "        #loop through lines in current image, see if a previous line matches, if so give it that number\n",
    "        #if not increase the global most recent number and assign that number\n",
    "        #if a line ends up having no number, call image a failure\n",
    "        #not sure what to do in this case, maybe skip image?\n",
    "        \n",
    "        hor_line_num = 1\n",
    "        for hor_line in super_x :\n",
    "            #TODO: generalise this\n",
    "            img_hor_lines.append([hor_line+hor_margin, hor_line_num])\n",
    "            hor_line_num += 1\n",
    "            \n",
    "            \n",
    "        for line in super_y : #pred_vert_lines = [[line, number]..]\n",
    "            #TODO: Track numbers from previous image\n",
    "            #TODO: Only one direction at the moment, will have to do reverse at some point\n",
    "            \n",
    "            margin = np.average(np.diff(super_y))*(3/8) # is 1.5 pmts hopefully\n",
    "            num_assigned = False\n",
    "            for prev_line in range(len(cor_lines)) :\n",
    "                if abs(cor_lines[prev_line] - line) < margin :\n",
    "                    line_num = cor_num[prev_line]\n",
    "                    img_vert_lines.append([line+vert_margin, cor_num[prev_line]])\n",
    "                    num_assigned = True\n",
    "                        \n",
    "            if line > max_prev_line + margin  :\n",
    "                prev_img_end_num += 1\n",
    "                img_vert_lines.append([line, prev_img_end_num])\n",
    "                num_assigned = True\n",
    "            \n",
    "            if not num_assigned :\n",
    "                failed_imgs.append(f'{base_name}')\n",
    "                img_vert_lines.append([line, 0])\n",
    "\n",
    "                #TODO: if image failes, skip image? manually ammend?\n",
    "                \n",
    "                \n",
    "                \n",
    "        \n",
    "        #draw_previous numbers and lines passed through\n",
    "        for num_prev_line in range(len(cor_lines)) :\n",
    "            cv2.line(line_img_drawn, (int(cor_lines[num_prev_line]), 0), (int(cor_lines[num_prev_line]), line_img.shape[0]),  color=[255, 255, 255] , thickness=2)\n",
    "            cv2.putText(line_img_drawn, f'{cor_num[num_prev_line]}', (int(cor_lines[num_prev_line]), int(line_img.shape[0]/3)), \\\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 3, (255,255,255), 2)\n",
    "    \n",
    "    #draw current numbers from returned values (img_vert_lines)\n",
    "    for num_current_line in img_vert_lines:\n",
    "        cv2.putText(line_img_drawn, f'{num_current_line[1]}', (int(num_current_line[0]), int(200)), \\\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 3, (0,255,0), 2)\n",
    "\n",
    "    for num_current_line in img_hor_lines:\n",
    "        cv2.putText(line_img_drawn, f'{num_current_line[1]}', (200, int(num_current_line[0])), \\\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 3, (0,255,0), 2)\n",
    "        \n",
    "    #Label PMTs\n",
    "    #TODO: move array converstion up\n",
    "    img_hor_lines = np.asarray(img_hor_lines)   #smod horizontal lines\n",
    "    img_vert_lines = np.asarray(img_vert_lines)   #smod vertical lines\n",
    "    \n",
    "    peaks_x_cor = np.array([ucor_x + hor_margin for ucor_x in peaks_x])   #pmt horizontal lines\n",
    "    peaks_y_cor = np.array([ucor_y + vert_margin for ucor_y in peaks_y])  #pmt vertical lines\n",
    "    print(f'hor_lines : {img_vert_lines[:,0]}')\n",
    "    \n",
    "    \n",
    "   # Work out the labels for pmts in the images based \n",
    "    id_info = np.zeros((len(peaks_x), len(peaks_y), 6)) # for each crossing of pmt lines: [xpos, ypos, smod_x, smod_x, smod_y, smod_pos_x, smod_pos_y]\n",
    "    for x in range(len(peaks_x)) :\n",
    "        for y in range(len(peaks_y)) :\n",
    "            id_info[x, y, 0] = peaks_x_cor[x]\n",
    "            id_info[x, y, 1] = peaks_y_cor[y]\n",
    "            \n",
    "            #Super module ID\n",
    "            #horizontal number\n",
    "            if peaks_x_cor[x] < np.min(img_hor_lines[:,0]) :\n",
    "                id_info[x, y, 3] = img_hor_lines[0,1] - 1\n",
    "                id_info[x, y, 5] = 3 - np.size(np.where(peaks_x_cor < np.min(img_hor_lines[:,0])))  + x\n",
    "\n",
    "            else :\n",
    "                indx = np.max(np.where(img_hor_lines[:,0] < peaks_x_cor[x]))\n",
    "               # print(f'indx x {indx} {img_hor_lines[indx, 1]} {np.where(img_hor_lines[:,0] < peaks_x_cor[x])}')\n",
    "                id_info[x, y, 3] = img_hor_lines[indx, 1]\n",
    "                id_info[x, y, 5] = np.size(np.where((peaks_x_cor > img_hor_lines[indx,0]) & (peaks_x_cor < peaks_x_cor[x])))\n",
    "\n",
    "            #vertical line numbering\n",
    "            if peaks_y_cor[y] < np.min(img_vert_lines[:,0]) :\n",
    "                id_info[x, y, 2] = img_vert_lines[0,1] - 1\n",
    "                id_info[x, y, 4] = 4 - np.size(np.where(peaks_y_cor < np.min(img_vert_lines[:,0])))  + y\n",
    "\n",
    "            else : \n",
    "                indx = np.max(np.where(img_vert_lines[:,0] < peaks_y_cor[y]))\n",
    "                #print(f'indx y {indx} : {img_vert_lines[indx, 0]} : {np.where((img_vert_lines[indx,0]< peaks_y_cor))} : {np.where((img_vert_lines[indx,0]< peaks_y_cor) & (peaks_y_cor < peaks_y_cor[y]))}')\n",
    "                #print(f'where y {np.where((img_vert_lines[indx,0]< peaks_y_cor) & (peaks_y_cor < peaks_y_cor[y]))}')\n",
    "                id_info[x, y, 2] = img_vert_lines[indx, 1]\n",
    "                id_info[x, y, 4] = np.size(np.where((img_vert_lines[indx,0]< peaks_y_cor) & (peaks_y_cor < peaks_y_cor[y])))\n",
    "\n",
    "   # print(id_info)\n",
    "    \n",
    "    #draw pmt ids\n",
    "    for b in id_info :\n",
    "        for a in b :\n",
    "            #print(a)\n",
    "            cv2.putText(line_img_drawn, f'{a[2:]}', (int(a[1])-100, int(a[0])+100), \\\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "\n",
    "    \n",
    "    #Write peak locations to file for use in feature finding\n",
    "    #[name:pmt_locs_x:pmt_locs_y:super_x:super_y]\n",
    "    pmt_loc = f'{base_name}:{[x+hor_margin for x in peaks_x]}:{[y+vert_margin for y in peaks_y]}:{super_x}:{super_y}'\n",
    "    pmt_file = open(f'{outdir}pmt_loc.txt', 'a')\n",
    "    pmt_file.write(f'{pmt_loc} \\n')\n",
    "    pmt_file.close()\n",
    "    \n",
    "    \n",
    "    #compare to validation\n",
    "    num_cor = 0\n",
    "    if base_name in val_coords :\n",
    "        #print([np.array(val_coords[base_name]['vert_lines']) + hor_margin, super_y])\n",
    "        #print([np.array(val_coords[base_name]['hor_lines']) + vert_margin, super_x])\n",
    "        for i in super_x :\n",
    "            for j in val_coords[base_name]['hor_lines'] :\n",
    "                #print(f'vert:{i} {j}')\n",
    "                cv2.line(line_img_drawn, (0, j), (line_img.shape[1], j),  color=[255, 0, 0] , thickness=2)\n",
    "                if abs(i - (j-hor_margin)) < 200 :\n",
    "                    print([i, (j-hor_margin)])\n",
    "                    num_cor += 1\n",
    "        \n",
    "        for k in super_y :\n",
    "            for l in val_coords[base_name]['vert_lines'] :\n",
    "                cv2.line(line_img_drawn, (l, 0), (l, line_img.shape[0]),  color=[255, 0, 0] , thickness=2) #PUT IN ANGLE CORRECTION\n",
    "                #print(f'hor:{k} {l}')\n",
    "                if abs(k - (l-vert_margin)) < 200 :\n",
    "                    print([k, (l-vert_margin)])\n",
    "                    num_cor += 1                    \n",
    "        #print(num_cor)\n",
    "    #plot all PMT lines\n",
    "    print(f\"Found {len(gaps_x)} horizontal gaps\")\n",
    "    print(f\"Found {len(gaps_y)} vertical gaps\")\n",
    "\n",
    "    num_modules =  len(gaps_y)\n",
    "   # print(super_x)\n",
    "\n",
    "   # plt.show()\n",
    "    cv2.imwrite(f\"{outdir}{name}_lines.png\", line_img_drawn)\n",
    "    \n",
    "    plot_data(x1, np.array(x_line_score), peaks_x, x2, np.array(y_line_score), peaks_y)\n",
    "    plt.savefig(f'{outdir}{name}_decisions.png')\n",
    "    plt.close()\n",
    "    #cv2.destroyAllWindows()\n",
    "    #super_y = [[line, num]...]\n",
    "    return num_modules, num_cor, img_vert_lines, super_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_info(img_start, img_end) :\n",
    "    #Finds image name in drone data and returns the useful bits in order of images taken\n",
    "    #theres some play in the data which could be accounted for here\n",
    "    #TODO:validation with epoch\n",
    "    csv_file = \"/home/dm3315/Documents/SK/PMT_learning/images/Raw/SK_TOW_2020_Image_Database-ImageDroneData.csv\"\n",
    "    rows = []\n",
    "    #img_start = 4147\n",
    "    #img_end = 4656\n",
    "    \n",
    "    with open(f'{csv_file}') as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    #print(readCSV)\n",
    "        for row in readCSV:\n",
    "            rows.append(row)\n",
    "    \n",
    "    rows = rows[img_start - 1:img_end]\n",
    "\n",
    "    if len(rows)%10 != 0 :\n",
    "        print(broken)\n",
    "        exit()\n",
    "    img_order = []\n",
    "    img_info = {}\n",
    "    \n",
    "    #Have to manually count index of information and add to dict\n",
    "    for i in rows :\n",
    "        img_info[f'{i[2][:-4]}'] = {'survey':i[0],'epoch':i[7],'depth':i[15], 'yaw':i[17], 'pitch':i[18], 'roll':i[19] }\n",
    "        img_order.append(f'{i[2][:4]}')\n",
    "\n",
    "    return img_info, np.unique(img_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#info = get_img_info(4147, 4656)\n",
    "#print(info)\n",
    "#yaw = [] \n",
    "#for i in info :\n",
    "    #print(i['name'])\n",
    "#    yaw.append(int(i['yaw']))\n",
    "#print(np.sort(np.unique(yaw)))\n",
    "#print(len(np.unique(yaw)))\n",
    "\n",
    "\n",
    "#Class structure to store info\n",
    "#class Image :\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject(init_vert_lines, init_hor_lines, init_yaw, end_yaw ) :\n",
    "    #function projects lines from one image to next, \n",
    "    #TODO: do same with depth for moving down tank to next ring\n",
    "    \n",
    "    global smod_track_lines\n",
    "    global smod_track_num\n",
    "    global ring_start_yaw\n",
    "    #TODO: line up images by looking at horizontal lines and label them\n",
    "    #todo: adjust guess by rescaling shift based on change in super module size\n",
    "    #TODO: account for getting back to start of ring\n",
    "\n",
    "    \n",
    "    \n",
    "    just_vert_lines = []\n",
    "    for vert_line in range(len(init_vert_lines)) :\n",
    "        just_vert_lines.append(init_vert_lines[vert_line][0])\n",
    "    \n",
    "    vert_smod_px = np.average(np.diff(just_vert_lines))\n",
    "    hor_smod_px = np.average(np.diff(init_hor_lines))\n",
    "    \n",
    "    scale_rat = vert_smod_px/hor_smod_px\n",
    "    smod_len = 9.6 #degrees\n",
    "    delta_y = int(end_yaw) - int(init_yaw)\n",
    "    \n",
    "    if abs(delta_y) > 340:\n",
    "        mag_delta_y = abs(360-delta_y)\n",
    "        sign_delta_y = delta_y/abs(delta_y)\n",
    "        delta_y = mag_delta_y * sign_delta_y\n",
    "        \n",
    "    shift_px = (delta_y / smod_len) #* scale_rat  #this is the fraction of a super module moved to the next image\n",
    "    \n",
    "    \n",
    "\n",
    "    print(f'smod_size:{vert_smod_px}')\n",
    "    print(f'aspect_ratio:{scale_rat}')\n",
    "    print(f'shift:{shift_px}')\n",
    "    print(f'initial lines:{init_vert_lines}')\n",
    "    \n",
    "    projected_vert_lines = []\n",
    "    if shift_px < 0 :\n",
    "        for i in range(len(init_vert_lines)) :\n",
    "            projected_vert_lines.append([(init_vert_lines[i][0]/vert_smod_px) + shift_px, init_vert_lines[i][1]] )\n",
    "    else :\n",
    "        for i in range(len(init_vert_lines)) :\n",
    "            projected_vert_lines.append([(init_vert_lines[i][0]/vert_smod_px) - shift_px, init_vert_lines[i][1]] )\n",
    "            \n",
    "            #smod_track_lines.append([init_vert_lines[i], smod_track_num] )\n",
    "\n",
    "           #         for i in range(len(init_vert_lines)) :\n",
    "           # projected_vert_lines.append(4000 - (init_vert_lines[i]+shift_px) )\n",
    "           # smod_track_lines.append([init_vert_lines[i], smod_track_num] )\n",
    "            \n",
    "    #return fraction of pmt moved\n",
    "    return [projected_vert_lines, hor_smod_px]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num images:51\n",
      "B755\n",
      "B756\n",
      "\n",
      " Processing image 1 of 51: B7550546_pred_substacks_far_unet.19\n",
      "B755\n",
      "Guess: 7 horizontal gaps above 1534.0459574468084, 9 vertical above 949.7852631578947\n",
      "hor_lines : [1709.84728805 3133.59662981]\n",
      "[1048.3922487223167, 1073]\n",
      "[1609.8472880463405, 1603]\n",
      "[3033.596629805161, 3010]\n",
      "Found 1 horizontal gaps\n",
      "Found 1 vertical gaps\n",
      "num_cor = 3\n",
      "yaws: 165, 159\n",
      "names: B755, B756\n",
      "smod_size:1423.7493417588203\n",
      "aspect_ratio:1.3698003275795534\n",
      "shift:-0.625\n",
      "initial lines:[[1.70984729e+03 1.00000000e+00]\n",
      " [3.13359663e+03 2.00000000e+00]]\n",
      "smods moved:[[[0.5759468506121246, 1.0], [1.5759468506121244, 2.0]], 1039.3845826235092]\n",
      "B756\n",
      "B757\n",
      "\n",
      " Processing image 2 of 51: B7560556_pred_substacks_far_unet.19\n",
      "B756\n",
      "Guess: 7 horizontal gaps above 1523.3634042553192, 9 vertical above 943.6626315789474\n",
      "max_lines:2205.9106496114214\n",
      "max_num:2.0\n",
      "info:[[0.5759468506121246, 1.0], [1.5759468506121244, 2.0]]\n",
      "old lines:[806.1739460832484, 2205.9106496114214]\n",
      "new_lines [468.24644549763036, 1867.9831490258034]  [1026.3735093696764, 2073.764906303237]\n",
      "hor_lines : [ 568.2464455  1967.98314903]\n",
      "[1026.3735093696764, 1099]\n",
      "[1867.9831490258034, 1833]\n",
      "Found 1 horizontal gaps\n",
      "Found 1 vertical gaps\n",
      "num_cor = 5\n",
      "yaws: 159, 152\n",
      "names: B756, B757\n",
      "smod_size:1399.7367035281732\n",
      "aspect_ratio:1.3364027121343285\n",
      "shift:-0.7291666666666667\n",
      "initial lines:[[5.68246445e+02 1.00000000e+00]\n",
      " [1.96798315e+03 2.00000000e+00]]\n",
      "smods moved:[[[-0.3231999987459716, 1.0], [0.6768000012540283, 2.0]], 1047.3913969335604]\n",
      "B757\n",
      "B758\n",
      "\n",
      " Processing image 3 of 51: B7570566_pred_substacks_far_unet.19\n",
      "B757\n",
      "Guess: 7 horizontal gaps above 1595.088510638298, 9 vertical above 987.9557894736843\n",
      "max_lines:940.2316605099079\n",
      "max_num:2.0\n",
      "info:[[-0.3231999987459716, 1.0], [0.6768000012540283, 2.0]]\n",
      "old lines:[-448.9995137923566, 940.2316605099079]\n",
      "new_lines [810.4265402843603, 2199.657714586625]  [1046.8909710391822, 2079.770017035775]\n",
      "hor_lines : [ 910.42654028 2199.65771459]\n",
      "[1046.8909710391822, 1066]\n",
      "[810.4265402843603, 810]\n",
      "[2199.657714586625, 2193]\n",
      "Found 1 horizontal gaps\n",
      "Found 1 vertical gaps\n",
      "num_cor = 8\n",
      "yaws: 152, 148\n",
      "names: B757, B758\n",
      "smod_size:1289.2311743022647\n",
      "aspect_ratio:1.2481918181023084\n",
      "shift:-0.4166666666666667\n",
      "initial lines:[[9.10426540e+02 2.00000000e+00]\n",
      " [2.19965771e+03 3.00000000e+00]]\n",
      "smods moved:[[[0.2895112154940603, 2.0], [1.2895112154940602, 3.0]], 1032.8790459965926]\n",
      "B758\n",
      "B759\n",
      "\n",
      " Processing image 4 of 51: B7580576_pred_substacks_far_unet.19\n",
      "B758\n",
      "Guess: 7 horizontal gaps above 1489.2774468085106, 10 vertical above 921.8536842105264\n",
      "max_lines:1755.303852812728\n",
      "max_num:3.0\n",
      "info:[[0.2895112154940603, 2.0], [1.2895112154940602, 3.0]]\n",
      "old lines:[394.0874231128863, 1755.303852812728]\n",
      "new_lines [1326.1979989468143, 2687.4144286466562]  [1049.8935264054514, 2058.752129471891]\n",
      "hor_lines : [1426.19799895 2687.41442865]\n",
      "Found 1 horizontal gaps\n",
      "Found 1 vertical gaps\n",
      "num_cor = 8\n",
      "yaws: 148, 147\n",
      "names: B758, B759\n",
      "smod_size:1261.216429699842\n",
      "aspect_ratio:1.2501419186656657\n",
      "shift:-0.10416666666666667\n",
      "initial lines:[[1426.19799895    3.        ]\n",
      " [2687.41442865    4.        ]]\n",
      "smods moved:[[[1.02664479864721, 3.0], [2.0266447986472103, 4.0]], 1008.8586030664394]\n",
      "B759\n",
      "B760\n",
      "\n",
      " Processing image 5 of 51: B7590586_pred_substacks_far_unet.19\n",
      "B759\n",
      "Guess: 7 horizontal gaps above 1663.7072340425532, 11 vertical above 1028.9526315789474\n",
      "max_lines:2753.6329170455674\n",
      "max_num:4.0\n",
      "info:[[1.02664479864721, 3.0], [2.0266447986472103, 4.0]]\n",
      "old lines:[1394.917803828084, 2753.6329170455674]\n",
      "new_lines [421.7219589257504, 1717.4038967877832, 3139.1521853607164]  [1039.8850085178874, 2038.234667802385]\n",
      "hor_lines : [ 421.72195893 1817.40389679 3239.15218536]\n",
      "Found 1 horizontal gaps\n",
      "Found 1 vertical gaps\n",
      "num_cor = 8\n",
      "yaws: 147, 134\n",
      "names: B759, B760\n",
      "smod_size:1408.7151132174831\n",
      "aspect_ratio:1.411043816278846\n",
      "shift:-1.3541666666666667\n",
      "initial lines:[[4.21721959e+02 0.00000000e+00]\n",
      " [1.81740390e+03 3.00000000e+00]\n",
      " [3.23915219e+03 4.00000000e+00]]\n",
      "smods moved:[[[-1.0548002759969848, 0.0], [-0.06405209365206943, 3.0], [0.9451997240030152, 4.0]], 998.3496592844976]\n",
      "B760\n",
      "B761\n",
      "\n",
      " Processing image 6 of 51: B7600596_pred_substacks_far_unet.19\n",
      "B760\n",
      "Guess: 7 horizontal gaps above 1030.5685106382978, 9 vertical above 637.9626315789474\n",
      "max_lines:1260.61471352419\n",
      "max_num:4.0\n",
      "info:[[-1.0548002759969848, 0.0], [-0.06405209365206943, 3.0], [0.9451997240030152, 4.0]]\n",
      "old lines:[-1406.7891832635933, -85.42640210247302, 1260.61471352419]\n",
      "new_lines [566.7983149025804, 1900.500263296472]  [1060.4024701873934, 2038.735093696763]\n",
      "hor_lines : [ 566.7983149 1900.5002633]\n",
      "Found 1 horizontal gaps\n",
      "Found 1 vertical gaps\n",
      "num_cor = 8\n",
      "yaws: 134, 133\n",
      "names: B760, B761\n",
      "smod_size:1333.7019483938916\n",
      "aspect_ratio:1.3632397779088459\n",
      "shift:-0.10416666666666667\n",
      "initial lines:[[ 566.7983149    0.       ]\n",
      " [1900.5002633    5.       ]]\n",
      "smods moved:[[[0.3208145786446612, 0.0], [1.3208145786446612, 5.0]], 978.3326235093696]\n",
      "B761\n",
      "B762\n",
      "\n",
      " Processing image 7 of 51: B7610606_pred_substacks_far_unet.19\n",
      "B761\n",
      "Guess: 7 horizontal gaps above 1532.8255319148936, 11 vertical above 948.8510526315789\n",
      "max_lines:1661.798963679177\n",
      "max_num:5.0\n",
      "info:[[0.3208145786446612, 0.0], [1.3208145786446612, 5.0]]\n",
      "old lines:[403.6367730525312, 1661.798963679177]\n",
      "new_lines [971.5113217482888, 2229.6735123749345]  [1030.87734241908, 1989.6933560477]\n",
      "hor_lines : [ 971.51132175 2229.67351237]\n",
      "[1030.87734241908, 1046]\n",
      "[2229.6735123749345, 2186]\n",
      "Found 1 horizontal gaps\n",
      "Found 2 vertical gaps\n",
      "num_cor = 10\n",
      "yaws: 133, 124\n",
      "names: B761, B762\n",
      "smod_size:1258.1621906266457\n",
      "aspect_ratio:1.3122039815179514\n",
      "shift:-0.9375\n",
      "initial lines:[[ 971.51132175    0.        ]\n",
      " [2229.67351237    6.        ]]\n",
      "smods moved:[[[-0.16533300198807144, 0.0], [0.8346669980119286, 6.0]], 958.8160136286201]\n",
      "B762\n",
      "B763\n",
      "\n",
      " Processing image 8 of 51: B7620616_pred_substacks_far_unet.19\n",
      "B762\n",
      "Guess: 7 horizontal gaps above 1792.3395744680852, 12 vertical above 1109.2289473684211\n",
      "max_lines:1091.0666785228602\n",
      "max_num:6.0\n",
      "info:[[-0.16533300198807144, 0.0], [0.8346669980119286, 6.0]]\n",
      "old lines:[-216.12131515802488, 1091.0666785228602]\n",
      "new_lines [1174.1179568193788, 2481.305950500264]  [1046.390545144804, 2030.227853492334]\n",
      "hor_lines : [1274.11795682 2481.3059505 ]\n",
      "[1046.390545144804, 1066]\n",
      "[1174.1179568193788, 1170]\n",
      "[2481.305950500264, 2476]\n",
      "Found 1 horizontal gaps\n",
      "Found 2 vertical gaps\n",
      "num_cor = 13\n",
      "yaws: 124, 121\n",
      "names: B762, B763\n",
      "smod_size:1207.187993680885\n",
      "aspect_ratio:1.227019938599908\n",
      "shift:-0.3125\n",
      "initial lines:[[1274.11795682    6.        ]\n",
      " [2481.3059505     7.        ]]\n",
      "smods moved:[[[0.7429428668018931, 6.0], [1.7429428668018931, 7.0]], 983.8373083475299]\n",
      "B763\n",
      "B764\n",
      "\n",
      " Processing image 9 of 51: B7630626_pred_substacks_far_unet.19\n",
      "B763\n",
      "Guess: 7 horizontal gaps above 1473.4348936170213, 9 vertical above 911.7594736842105\n",
      "max_lines:2331.5417401457867\n",
      "max_num:7.0\n",
      "info:[[0.7429428668018931, 6.0], [1.7429428668018931, 7.0]]\n",
      "old lines:[993.8376853801207, 2331.5417401457867]\n",
      "new_lines [1619.352290679305, 2957.056345444971]  [1046.8909710391822, 2029.7274275979553]\n",
      "hor_lines : [1619.35229068 2957.05634544]\n",
      "[2029.7274275979553, 2003]\n",
      "[1619.352290679305, 1606]\n",
      "[2957.056345444971, 2926]\n",
      "Found 1 horizontal gaps\n",
      "Found 1 vertical gaps\n",
      "num_cor = 16\n",
      "yaws: 121, 114\n",
      "names: B763, B764\n",
      "smod_size:1337.7040547656661\n",
      "aspect_ratio:1.3610647487064111\n",
      "shift:-0.7291666666666667\n",
      "initial lines:[[1619.35229068    0.        ]\n",
      " [2957.05634544    8.        ]]\n",
      "smods moved:[[[0.4813793318374471, 0.0], [1.481379331837447, 8.0]], 982.8364565587731]\n",
      "B764\n",
      "B765\n",
      "\n",
      " Processing image 10 of 51: B7640636_pred_substacks_far_unet.19\n",
      "B764\n",
      "Guess: 7 horizontal gaps above 1934.0910638297873, 10 vertical above 1196.8673684210526\n",
      "max_lines:2132.827399250534\n",
      "max_num:8.0\n",
      "info:[[0.4813793318374471, 0.0], [1.481379331837447, 8.0]]\n",
      "old lines:[693.0696320046152, 2132.827399250534]\n",
      "new_lines [1271.1690363349132, 2710.9268035808323]  [1035.8816013628618, 2101.7887563884155]\n",
      "hor_lines : [1271.16903633 2710.92680358]\n",
      "Found 1 horizontal gaps\n",
      "Found 2 vertical gaps\n",
      "num_cor = 16\n",
      "yaws: 114, 111\n",
      "names: B764, B765\n",
      "smod_size:1439.757767245919\n",
      "aspect_ratio:1.350734686841841\n",
      "shift:-0.3125\n",
      "initial lines:[[1271.16903633    0.        ]\n",
      " [2710.92680358    9.        ]]\n",
      "smods moved:[[[0.5704047949965254, 0.0], [1.5704047949965254, 9.0]], 1065.9071550255537]\n",
      "B765\n",
      "B766\n",
      "\n",
      " Processing image 11 of 51: B7650646_pred_substacks_far_unet.19\n",
      "B765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess: 7 horizontal gaps above 1350.3804255319149, 10 vertical above 835.69\n",
      "max_lines:2196.581999194192\n",
      "max_num:9.0\n",
      "info:[[0.5704047949965254, 0.0], [1.5704047949965254, 9.0]]\n",
      "old lines:[797.8458222589632, 2196.581999194192]\n",
      "new_lines [945.9978936282255, 2344.7340705634547]  [1039.8850085178876, 2082.7725724020443]\n",
      "hor_lines : [1045.99789363 2444.73407056]\n",
      "[1039.8850085178876, 1059]\n",
      "[2344.7340705634547, 2210]\n",
      "Found 1 horizontal gaps\n",
      "Found 1 vertical gaps\n",
      "num_cor = 18\n",
      "yaws: 111, 106\n",
      "names: B765, B766\n",
      "smod_size:1398.7361769352292\n",
      "aspect_ratio:1.3412147439228645\n",
      "shift:-0.5208333333333334\n",
      "initial lines:[[1045.99789363    0.        ]\n",
      " [2444.73407056    9.        ]]\n",
      "smods moved:[[[0.2269830961523981, 0.0], [1.2269830961523982, 9.0]], 1042.8875638841566]\n",
      "B766\n",
      "B767\n",
      "\n",
      " Processing image 12 of 51: B7660656_pred_substacks_far_unet.19\n",
      "B766\n",
      "Guess: 7 horizontal gaps above 1139.2553191489362, 9 vertical above 704.8\n",
      "max_lines:1556.0200322848934\n",
      "max_num:9.0\n",
      "info:[[0.2269830961523981, 0.0], [1.2269830961523982, 9.0]]\n",
      "old lines:[287.8525757288113, 1556.0200322848934]\n",
      "new_lines [1378.7256450763562, 2646.893101632438]  [1053.3965076660986, 2083.2729982964224]\n",
      "hor_lines : [1478.72564508 2646.89310163]\n",
      "[1053.3965076660986, 1056]\n",
      "[1378.7256450763562, 1363]\n",
      "[2646.893101632438, 2786]\n",
      "Found 1 horizontal gaps\n",
      "Found 1 vertical gaps\n",
      "num_cor = 21\n",
      "yaws: 106, 100\n",
      "names: B766, B767\n",
      "smod_size:1168.167456556082\n",
      "aspect_ratio:1.1342791754000703\n",
      "shift:-0.625\n",
      "initial lines:[[1478.72564508    9.        ]\n",
      " [2646.89310163   10.        ]]\n",
      "smods moved:[[[0.6408507449230287, 9.0], [1.6408507449230285, 10.0]], 1029.8764906303238]\n",
      "B767\n",
      "B768\n",
      "\n",
      " Processing image 13 of 51: B7670666_pred_substacks_far_unet.19\n",
      "B767\n",
      "Guess: 7 horizontal gaps above 1254.8255319148936, 10 vertical above 776.4636842105264\n",
      "max_lines:2346.0104568407132\n",
      "max_num:10.0\n",
      "info:[[0.6408507449230287, 9.0], [1.6408507449230285, 10.0]]\n",
      "old lines:[916.2579555242313, 2346.0104568407132]\n",
      "new_lines [267.6408636124276, 1706.3981042654032, 3127.1458662453924]  [1025.3726575809198, 2068.2602214650765]\n",
      "hor_lines : [ 267.64086361 1706.39810427 3127.14586625]\n",
      "Found 1 horizontal gaps\n",
      "Found 1 vertical gaps\n",
      "num_cor = 21\n",
      "yaws: 100, 92\n",
      "names: B767, B768\n",
      "smod_size:1429.7525013164823\n",
      "aspect_ratio:1.3709555572716545\n",
      "shift:-0.8333333333333334\n",
      "initial lines:[[ 267.64086361    0.        ]\n",
      " [1706.39810427    0.        ]\n",
      " [3127.14586625   11.        ]]\n",
      "smods moved:[[[-0.6461394914858876, 0.0], [0.3601586190809426, 0.0], [1.3538605085141127, 11.0]], 1042.8875638841566]\n",
      "B768\n",
      "B769\n",
      "\n",
      " Processing image 14 of 51: B7680676_pred_substacks_far_unet.19\n",
      "B768\n",
      "Guess: 8 horizontal gaps above 1666.0791489361702, 11 vertical above 1031.4294736842105\n",
      "max_lines:1892.6777417011867\n",
      "max_num:11.0\n",
      "info:[[-0.6461394914858876, 0.0], [0.3601586190809426, 0.0], [1.3538605085141127, 11.0]]\n",
      "old lines:[-903.2938222798564, 503.4966287364979, 1892.6777417011867]\n",
      "new_lines [576.3033175355451, 1976.5402843601896, 3372.274881516588]  [1051.895229982964, 2061.2542589437817]\n",
      "hor_lines : [ 676.30331754 2076.54028436 3372.27488152]\n",
      "[1051.895229982964, 1063]\n",
      "[1976.5402843601896, 2000]\n",
      "Found 2 horizontal gaps\n",
      "Found 1 vertical gaps\n",
      "num_cor = 23\n",
      "yaws: 92, 89\n",
      "names: B768, B769\n",
      "smod_size:1347.9857819905214\n",
      "aspect_ratio:1.3354869212180487\n",
      "shift:-0.3125\n",
      "initial lines:[[ 676.30331754    0.        ]\n",
      " [2076.54028436   11.        ]\n",
      " [3372.27488152   12.        ]]\n",
      "smods moved:[[[0.1892139843543993, 0.0], [1.2279763997538893, 11.0], [2.189213984354399, 12.0]], 1009.3590289608176]\n",
      "B769\n",
      "B770\n",
      "\n",
      " Processing image 15 of 51: B7690686_pred_substacks_far_unet.19\n",
      "B769\n",
      "Guess: 7 horizontal gaps above 1832.659574468085, 11 vertical above 1134.7221052631578\n",
      "max_lines:2938.3770742610373\n",
      "max_num:12.0\n",
      "info:[[0.1892139843543993, 0.0], [1.2279763997538893, 11.0], [2.189213984354399, 12.0]]\n",
      "old lines:[253.96422539321256, 1648.1978128028966, 2938.3770742610373]\n",
      "new_lines [938.9942074776199, 2281.2006319115326]  [1061.9037478705282, 2076.2670357751276]\n",
      "hor_lines : [ 938.99420748 2281.20063191]\n",
      "[1061.9037478705282, 1066]\n",
      "[2281.2006319115326, 2283]\n",
      "Found 1 horizontal gaps\n",
      "Found 2 vertical gaps\n",
      "num_cor = 25\n",
      "yaws: 89, 81\n",
      "names: B769, B770\n",
      "smod_size:1342.2064244339126\n",
      "aspect_ratio:1.3232009088248338\n",
      "shift:-0.8333333333333334\n",
      "initial lines:[[ 938.99420748    0.        ]\n",
      " [2281.20063191    0.        ]]\n",
      "smods moved:[[[-0.13374332215182017, 0.0], [0.8662566778481801, 0.0]], 1014.3632879045995]\n",
      "B770\n",
      "B771\n",
      "\n",
      " Processing image 16 of 51: B7700696_pred_substacks_far_unet.19\n",
      "B770\n",
      "Guess: 7 horizontal gaps above 1616.8978723404255, 10 vertical above 1000.9331578947368\n",
      "max_lines:1174.8292580116354\n",
      "max_num:0.0\n",
      "info:[[-0.13374332215182017, 0.0], [0.8662566778481801, 0.0]]\n",
      "old lines:[-181.38453872348882, 1174.8292580116354]\n",
      "new_lines [1268.1674565560822, 2624.381253291206]  [1055.3982112436115, 2072.2636286201023]\n",
      "hor_lines : [1368.16745656 2624.38125329]\n",
      "[1055.3982112436115, 1076]\n",
      "[1268.1674565560822, 1283]\n",
      "[2624.381253291206, 2633]\n",
      "Found 1 horizontal gaps\n",
      "Found 1 vertical gaps\n",
      "num_cor = 28\n",
      "yaws: 81, 71\n",
      "names: B770, B771\n",
      "smod_size:1256.2137967351239\n",
      "aspect_ratio:1.2353786206793729\n",
      "shift:-1.0416666666666667\n",
      "initial lines:[[1368.16745656    0.        ]\n",
      " [2624.38125329   13.        ]]\n",
      "smods moved:[[[0.047453242788175976, 0.0], [1.047453242788176, 13.0]], 1016.8654173764908]\n",
      "B771\n",
      "B772\n",
      "\n",
      " Processing image 17 of 51: B7710706_pred_substacks_far_unet.19\n",
      "B771\n",
      "Guess: 7 horizontal gaps above 1459.1531914893617, 9 vertical above 903.2868421052632\n",
      "max_lines:1400.134445230914\n",
      "max_num:13.0\n",
      "info:[[0.047453242788175976, 0.0], [1.047453242788176, 13.0]]\n",
      "old lines:[63.43091705819162, 1400.134445230914]\n",
      "new_lines [1461.2690889942076, 2797.97261716693]  [1051.394804088586, 2057.2508517887563]\n",
      "hor_lines : [1561.26908899 2797.97261717]\n",
      "Found 1 horizontal gaps\n",
      "Found 1 vertical gaps\n",
      "num_cor = 28\n",
      "yaws: 71, 70\n",
      "names: B771, B772\n",
      "smod_size:1236.7035281727224\n",
      "aspect_ratio:1.2295034970464918\n",
      "shift:-0.10416666666666667\n",
      "initial lines:[[1561.26908899   13.        ]\n",
      " [2797.97261717   14.        ]]\n",
      "smods moved:[[[1.1582774465971188, 13.0], [2.158277446597119, 14.0]], 1005.8560477001704]\n",
      "B772\n",
      "B773\n",
      "\n",
      " Processing image 18 of 51: B7720716_pred_substacks_far_unet.19\n",
      "B772\n"
     ]
    }
   ],
   "source": [
    "#Need segemnted files for input (could be done with just points maybe?\n",
    "#need the csv file with information\n",
    "#Raw images useful for overlay\n",
    "#outputs txt file with positions of pmts and super modules horizontally and vertically\n",
    "\n",
    "\n",
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "method  ='guess_meth'\n",
    "seg_files = 'ring_avg'\n",
    "\n",
    "work_dir = f\"/home/dm3315/Documents/SK/PMT_learning/images/datasets/substacks_far/output/{seg_files}/\"\n",
    "#out_dir = f\"/home/dm3315/Documents/SK/PMT_learning/images/ring_reco/four_gaps/{method}/\"\n",
    "out_dir = f\"/home/dm3315/Documents/SK/PMT_learning/images/datasets/substacks_far/output/{seg_files}/smodule/{method}/\"\n",
    "\n",
    "#indir = \"/home/dm3315/Documents/SK/PMT_learning/images/Raw/ring_avg/\"\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(f'{work_dir}'):\n",
    "    f.extend(filenames)\n",
    "    break\n",
    "f = [x[:-4] for x in f]\n",
    "\n",
    "#info, order = get_img_info(4577, 4656)\n",
    "info, order = get_img_info(4147, 4656)\n",
    "#print(info)\n",
    "tot_mods = 0\n",
    "tot_cor = 0\n",
    "img_num = 1\n",
    "\n",
    "#global variables that may not be used\n",
    "smod_track_num = 0\n",
    "smod_count_num = 0\n",
    "prev_img_end_num = 0\n",
    "prev_hor_end_num = 0\n",
    "smod_count_lines = [] #just counting lines\n",
    "smod_track_lines = [] #applying unique numbers\n",
    "failed_imgs = []\n",
    "\n",
    "#get list of images in order they were taken (i.e. going round the ring)\n",
    "os.chdir(f\"{work_dir}\")\n",
    "#print(info)\n",
    "pmt_info_file = open(f'/home/dm3315/Documents/SK/PMT_learning/images/datasets/substacks_far/output/{seg_files}/smodule/{method}/pmt_loc.txt', 'w')\n",
    "pmt_info_file.close()\n",
    "num_images = len(order) - 1\n",
    "print(f'num images:{num_images}')\n",
    "\n",
    "#loop em\n",
    "i = 0\n",
    "while i < num_images :\n",
    "    \n",
    "    #Get list of image names from files \n",
    "    if len(glob.glob(f\"{order[i]}*\")) > 1 :\n",
    "        print(f'Duplicate images: {glob.glob(f\"{order[i]}*\")}')\n",
    "        continue\n",
    "        \n",
    "    print(order[i])\n",
    "    print(order[i+1])\n",
    "    filename = glob.glob(f\"{order[i]}*\")[0]\n",
    "    \n",
    "    if len(glob.glob(f\"{order[i+1]}*\")) == 0 :\n",
    "        order = np.delete(order, i+1)\n",
    "        num_images -= 1\n",
    "    next_filename = glob.glob(f\"{order[i+1]}*\")[0]\n",
    "    print(f'\\n Processing image {img_num} of {len(f)}: {filename[:-4]}')\n",
    "\n",
    "    \n",
    "    #TODO:change this to do multiple rings\n",
    "    if img_num == 1 :\n",
    "        smod_shift = [[], 1]\n",
    "        ring_start_yaw = None\n",
    "    num, num_cor, vert, hor = find_super_modules(work_dir, out_dir, filename[:-4], smod_shift)\n",
    "    tot_mods += num\n",
    "    tot_cor += num_cor\n",
    "    print(f'num_cor = {tot_cor}')\n",
    "    \n",
    "    #TODO:decide if ring is finished:\n",
    "    \n",
    "    \n",
    "        #get start of ring and catch end of ring\n",
    "    if seg_files=='ring_avg':\n",
    "        yaw_1 = int(info[filename[:8]]['yaw'])\n",
    "        yaw_2 = int(info[next_filename[:8]]['yaw'])\n",
    "        depth_1 = info[filename[:8]]['depth']\n",
    "        depth_2 = info[next_filename[:8]]['depth']\n",
    "        if yaw_2 - yaw_1 < 0 :\n",
    "            if ring_start_yaw == None :\n",
    "                ring_start_yaw = yaw_1\n",
    "            else :\n",
    "                if (abs(yaw_1 - ring_start_yaw < 10)) and (yaw_1 < ring_start_yaw) and (img_num > 20) :\n",
    "                    print(f'ring complete at depth :{depth_1}')\n",
    "                    #ring_start_yaw = None\n",
    "                    #TODO: get to next ring depth, project initial img lines back to last img lines and label\n",
    "                    #TODO: reproject horizontal line labels to next depth\n",
    "                    #TODO: other way around ring?\n",
    "                    \n",
    "        \n",
    "        #Reproject image horizontally to next one\n",
    "        print(f'yaws: {yaw_1}, {yaw_2}')\n",
    "        print(f'names: {order[i]}, {order[i+1]}')\n",
    "        #scaled by horizontal spacing, basically aspect ratio\n",
    "        smod_shift = reproject(vert, hor, yaw_1, yaw_2 )\n",
    "        print(f'smods moved:{smod_shift}')\n",
    "    i += 1\n",
    "    img_num += 1\n",
    "    \n",
    "pmt_info_file.close()\n",
    "print(f\"found {prev_img_end_num} Super modules horizontally in ring. {tot_cor} of 64 are correct\")\n",
    "print(f'Images with failed labels: {failed_imgs}')\n",
    "\n",
    "print(f'time taken = {time.time() - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpath = '/home/dm3315/Documents/SK/PMT_learning/images/Raw/large_labeled/frames/B5310.png'   \n",
    "imge = cv2.imread(f'{inpath}')\n",
    "out = UndistortImage(imge)\n",
    "\n",
    "cv2.imwrite(\"/home/dm3315/Documents/SK/PMT_learning/images/Raw/undistorted/orig.png\", imge)\n",
    "cv2.imwrite(\"/home/dm3315/Documents/SK/PMT_learning/images/Raw/undistorted/undist.png\", out)\n",
    "#cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#indir = \"/home/dm3315/Documents/SK/PMT_learning/images/Raw/ring_avg/\"\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(f'{indir}'):\n",
    "    f.extend(filenames)\n",
    "    break\n",
    "\n",
    "for k in f :\n",
    "    orig = cv2.imread(f\"{indir}{k}\")\n",
    "    undist = UndistortImage(orig)\n",
    "    cv2.imwrite(f\"{indir}udist/{k}\", undist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertMasksBGR(BGR_img) :\n",
    "    lower_pmts = np.array([254, 0, 0], dtype = \"uint16\")\n",
    "    upper_pmts = np.array([255,0,0], dtype = \"uint16\")\n",
    "    pmt_mask = cv2.inRange(BGR_img, lower_pmts, upper_pmts)\n",
    "    pmt_mask[pmt_mask == 255] = 1\n",
    "    return pmt_mask\n",
    "\n",
    "inpath = \"/home/dm3315/Documents/SK/PMT_learning/images/datasets/bolt_pmt_blur/output/ring_avg/B7550546.png_pred_noverlay.png\"\n",
    "img = cv2.imread(f\"{inpath}\")\n",
    "print(np.unique(img))\n",
    "\n",
    "pmts = ConvertMasksBGR(img)\n",
    "#pmts_gray = cv2.cvtColor(pmts, cv2.COLOR_BGR2GRAY)\n",
    "print(np.unique(pmts))\n",
    "cv2.imshow(\"img\", pmts)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply convolution \n",
    "\n",
    "#prepare the 5x5 shaped filter\n",
    "kernel = np.array([[1, 1, 1, 1, 1], \n",
    "                   [1, 1, 1, 1, 1], \n",
    "                   [1, 1, 1, 1, 1], \n",
    "                   [1, 1, 1, 1, 1], \n",
    "                   [1, 1, 1, 1, 1]])\n",
    "kernel = np.round(kernel/sum(kernel))\n",
    "\n",
    "#filter the source image\n",
    "img_rst = cv2.filter2D(img_in,-1,kernel)\n",
    "\n",
    "#save result image\n",
    "cv2.imwrite('/home/dm3315/Documents/SK/PMT_learning/images/conv.png',img_rst)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
